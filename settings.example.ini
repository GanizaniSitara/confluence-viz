[confluence]
; Base URL for your Confluence instance (e.g., http://localhost:8090 or https://your-domain.atlassian.net)
base_url = http://example.atlassian.net 
username = your_username
password = your_password
verify_ssl = True

[data]
; Directory for storing sampled pickle files (default: temp)
; Example: pickle_dir = /path/to/pickles or C:\pickles
pickle_dir = temp
; Optional: Path to a directory containing pre-generated full pickle files (e.g., from a remote server or shared location)
; If set, explore_pickle_content.py will look for <SPACE_KEY>_full.pkl files here when 'full content' is requested.
; Example: remote_full_pickle_dir = /mnt/shared_pickles/
remote_full_pickle_dir =

[visualization]
; Default number of clusters
default_clusters = 20
; Minimum pages filter default
default_min_pages = 5

# Open-WebUI Document Extractor Settings
# Update these values with your Open-WebUI credentials

[OpenWebUI]
# Base URL of your Open-WebUI instance
base_url = http://localhost:8080

# Your Open-WebUI username
username = your_username

# Your Open-WebUI password
password = your_password

# Local directory containing documents to upload
upload_dir = /path/to/local/documents

# Name of the knowledge base/collection to create or use
collection_name = DOCS

# Optional settings (uncomment to use)
# skip_macro_files = false
# temp_directory = /tmp/openwebui_docs


# settings.example.ini
# Rename to settings.ini and fill in real values.

[ tika ]
# URL of the running Apache Tika server (out‑of‑process)
# Example: http://localhost:9998
url = http://localhost:9998

[ ollama ]
# URL of the local Ollama embeddings API
# Example: http://localhost:11434/api/embeddings
url = http://localhost:11434/api/embeddings
# Model identifier to pull and use via Ollama
# Example: nomic-embed-text-v1
model = nomic-embed-text-v1

[ database ]
# PostgreSQL connection string (DSN)
# Format: postgresql://user:pass@host:port/dbname
dsn = postgresql://user:pass@localhost:5432/dbname
# Name of the table to store documents
table = documents

[ pgvector ]
# Dimensionality of the embedding vectors
# Must match your chosen model (e.g., 768 for nomic-embed-text-v1)
dim = 768

[ pipeline ]
# Directory containing documents to ingest
# Example: /path/to/docs
docs_dir = /path/to/docs
# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
log_level = INFO
